{
  "per_question": [
    {
      "id": "academic-standards:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.942266047000885,
      "sbert_cosine_chunk": 0.6557410359382629,
      "bertscore_f1": 0.7227668166160583,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9060254355346823
    },
    {
      "id": "academic-standards:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6321160197257996,
      "sbert_cosine_chunk": 0.8051271438598633,
      "bertscore_f1": 0.1992236077785492,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6240505200038379
    },
    {
      "id": "academic-standards:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8763885498046875,
      "sbert_cosine_chunk": 0.7153315544128418,
      "bertscore_f1": 0.5799208879470825,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.6644577980041504,
      "sbert_cosine_chunk": 0.5256456136703491,
      "bertscore_f1": 0.4451504051685333,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3992639183998108,
      "sbert_cosine_chunk": 0.6302188634872437,
      "bertscore_f1": 0.11536212265491486,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8529278650606567
    },
    {
      "id": "academic-standards:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.38304901123046875,
      "sbert_cosine_chunk": 0.7625376582145691,
      "bertscore_f1": 0.19695065915584564,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6394520998001099,
      "sbert_cosine_chunk": 0.5322956442832947,
      "bertscore_f1": 0.5337506532669067,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.7927711009979248,
      "sbert_cosine_chunk": 0.7718154191970825,
      "bertscore_f1": 0.43412718176841736,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5957849025726318,
      "sbert_cosine_chunk": 0.7376847863197327,
      "bertscore_f1": 0.23206590116024017,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8350887298583984,
      "sbert_cosine_chunk": 0.7153540253639221,
      "bertscore_f1": 0.5648179054260254,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 1.0000001192092896,
      "sbert_cosine_chunk": 0.8297892808914185,
      "bertscore_f1": 1.0,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.7606395682357036
    },
    {
      "id": "degree-requirements:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4505040943622589,
      "sbert_cosine_chunk": 0.7043664455413818,
      "bertscore_f1": 0.09778348356485367,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.5012658353418871
    },
    {
      "id": "degree-requirements:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7451068162918091,
      "sbert_cosine_chunk": 0.7469423413276672,
      "bertscore_f1": 0.365650475025177,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.728844940662384,
      "sbert_cosine_chunk": 0.6983538269996643,
      "bertscore_f1": 0.49360954761505127,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7701656818389893,
      "sbert_cosine_chunk": 0.7883440852165222,
      "bertscore_f1": 0.33580511808395386,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "degree-requirements:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6463158130645752,
      "sbert_cosine_chunk": 0.7793741226196289,
      "bertscore_f1": 0.341644287109375,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.639704167842865,
      "sbert_cosine_chunk": 0.7161824703216553,
      "bertscore_f1": 0.08460912853479385,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "grading:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8367229700088501,
      "sbert_cosine_chunk": 0.7468438744544983,
      "bertscore_f1": 0.36466550827026367,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5187694430351257,
      "sbert_cosine_chunk": 0.6419796347618103,
      "bertscore_f1": -0.14983779191970825,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3599596321582794,
      "sbert_cosine_chunk": 0.41336789727211,
      "bertscore_f1": 0.05764026939868927,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6336471438407898,
      "sbert_cosine_chunk": 0.727580726146698,
      "bertscore_f1": 0.14327992498874664,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7795607447624207,
      "sbert_cosine_chunk": 0.4811745584011078,
      "bertscore_f1": 0.4453834891319275,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "grading:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.44690054655075073,
      "sbert_cosine_chunk": 0.6975054144859314,
      "bertscore_f1": 0.09696450084447861,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "grading:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7169412970542908,
      "sbert_cosine_chunk": 0.7057989239692688,
      "bertscore_f1": 0.44571301341056824,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9060254355346823
    },
    {
      "id": "graduation:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.39051637053489685,
      "sbert_cosine_chunk": 0.3157649040222168,
      "bertscore_f1": 0.16723667085170746,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7053638100624084,
      "sbert_cosine_chunk": 0.7614745497703552,
      "bertscore_f1": 0.3081984519958496,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5051997303962708,
      "sbert_cosine_chunk": 0.6719333529472351,
      "bertscore_f1": 0.1873796135187149,
      "recall@1": 0.5,
      "recall@3": 0.5,
      "recall@5": 0.5,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.9401460289955139,
      "sbert_cosine_chunk": 0.8323267102241516,
      "bertscore_f1": 0.5288798213005066,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6849271655082703,
      "sbert_cosine_chunk": 0.7463585734367371,
      "bertscore_f1": 0.5330601930618286,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.9074373245239258,
      "sbert_cosine_chunk": 0.7121843099594116,
      "bertscore_f1": 0.7262447476387024,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5273024439811707,
      "sbert_cosine_chunk": 0.7150681018829346,
      "bertscore_f1": 0.24107083678245544,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.13591739535331726,
      "sbert_cosine_chunk": 0.3900417387485504,
      "bertscore_f1": 0.1163654550909996,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "graduation:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6440578699111938,
      "sbert_cosine_chunk": 0.47918546199798584,
      "bertscore_f1": 0.3253780007362366,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.7457920908927917,
      "sbert_cosine_chunk": 0.7020137906074524,
      "bertscore_f1": 0.3979905843734741,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.9454867243766785,
      "sbert_cosine_chunk": 0.9365875124931335,
      "bertscore_f1": 0.6877412796020508,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8965990543365479,
      "sbert_cosine_chunk": 0.7755389213562012,
      "bertscore_f1": 0.7374968528747559,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.8302475810050964,
      "sbert_cosine_chunk": 0.9304870367050171,
      "bertscore_f1": 0.18168170750141144,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.672939658164978,
      "sbert_cosine_chunk": 0.9113665223121643,
      "bertscore_f1": 0.12415549904108047,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0013",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5949479937553406,
      "sbert_cosine_chunk": 0.9883921146392822,
      "bertscore_f1": 0.19935639202594757,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0014",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.4914110004901886,
      "sbert_cosine_chunk": 0.7589297890663147,
      "bertscore_f1": 0.2504783570766449,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0016",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5206471085548401,
      "sbert_cosine_chunk": 0.9147281646728516,
      "bertscore_f1": 0.059550877660512924,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0017",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.8441292643547058,
      "sbert_cosine_chunk": 0.9732155203819275,
      "bertscore_f1": 0.42053890228271484,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "graduation:q0011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7532219886779785,
      "sbert_cosine_chunk": 0.9674393534660339,
      "bertscore_f1": 0.5121095776557922,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.7123270630836487,
      "sbert_cosine_chunk": 0.9674393534660339,
      "bertscore_f1": 0.45216104388237,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "admissions:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5434126257896423,
      "sbert_cosine_chunk": 0.5538897514343262,
      "bertscore_f1": 0.07557948678731918,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "admissions:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3590315282344818,
      "sbert_cosine_chunk": 0.47587016224861145,
      "bertscore_f1": 0.14383827149868011,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "admissions:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5829096436500549,
      "sbert_cosine_chunk": 0.7288353443145752,
      "bertscore_f1": 0.1636895090341568,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "admissions:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7998660206794739,
      "sbert_cosine_chunk": 0.8202840685844421,
      "bertscore_f1": 0.14467032253742218,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9469024295259745
    },
    {
      "id": "admissions:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9554653763771057,
      "sbert_cosine_chunk": 0.9817564487457275,
      "bertscore_f1": 0.6491879820823669,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "campus-life:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.7528431415557861,
      "sbert_cosine_chunk": 0.9468187093734741,
      "bertscore_f1": 0.6075208783149719,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-support-services:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7441551685333252,
      "sbert_cosine_chunk": 0.9659548997879028,
      "bertscore_f1": 0.06446265429258347,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "registration:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4525846242904663,
      "sbert_cosine_chunk": 0.5281993746757507,
      "bertscore_f1": 0.08214794844388962,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "registration:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5085844397544861,
      "sbert_cosine_chunk": 0.6323662996292114,
      "bertscore_f1": 0.09112956374883652,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "registration:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.8518626689910889,
      "sbert_cosine_chunk": 0.8377611637115479,
      "bertscore_f1": 0.3322703242301941,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "registration:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.5742354989051819,
      "sbert_cosine_chunk": 0.9895772933959961,
      "bertscore_f1": 0.05983481928706169,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6509209298071326
    },
    {
      "id": "fees-financial-support:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8948491811752319,
      "sbert_cosine_chunk": 0.8784591555595398,
      "bertscore_f1": 0.5278690457344055,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9047172294870751
    },
    {
      "id": "fees-financial-support:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.48785027861595154,
      "sbert_cosine_chunk": 0.7015815377235413,
      "bertscore_f1": 0.052773699164390564,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "registration:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8237040042877197,
      "sbert_cosine_chunk": 0.9499640464782715,
      "bertscore_f1": 0.30075803399086,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "registration:q0007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5156394243240356,
      "sbert_cosine_chunk": 0.5002225041389465,
      "bertscore_f1": 0.017145659774541855,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4513561427593231,
      "sbert_cosine_chunk": 0.5573474764823914,
      "bertscore_f1": 0.003400243353098631,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8430402278900146,
      "sbert_cosine_chunk": 0.6935610175132751,
      "bertscore_f1": 0.8208063244819641,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.7328286204777911
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5850353837013245,
      "sbert_cosine_chunk": 0.6190719604492188,
      "bertscore_f1": 0.11765025556087494,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.45204514265060425,
      "sbert_cosine_chunk": 0.5978745222091675,
      "bertscore_f1": 0.08310501277446747,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.6182885020492784
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3910287022590637,
      "sbert_cosine_chunk": 0.5436946749687195,
      "bertscore_f1": 0.06659328192472458,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9359230399131775,
      "sbert_cosine_chunk": 0.6666837930679321,
      "bertscore_f1": 0.7000747323036194,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5706417189553201
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6650454998016357,
      "sbert_cosine_chunk": 0.7335520386695862,
      "bertscore_f1": 0.10018357634544373,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5726858377456665,
      "sbert_cosine_chunk": 0.5876150131225586,
      "bertscore_f1": 0.4337736666202545,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6797310500037655
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.545729398727417,
      "sbert_cosine_chunk": 0.5617653131484985,
      "bertscore_f1": 0.11988365650177002,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.38685280723454163
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.47735458612442017,
      "sbert_cosine_chunk": 0.5874930620193481,
      "bertscore_f1": 0.24100655317306519,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.5012658353418871
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4224942922592163,
      "sbert_cosine_chunk": 0.5013942718505859,
      "bertscore_f1": 0.07790682464838028,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.5012658353418871
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4668022394180298,
      "sbert_cosine_chunk": 0.5052818059921265,
      "bertscore_f1": 0.0891084149479866,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req013",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3780319392681122,
      "sbert_cosine_chunk": 0.5059871673583984,
      "bertscore_f1": 0.11919781565666199,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5706417189553201
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req014",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5579370260238647,
      "sbert_cosine_chunk": 0.5181348323822021,
      "bertscore_f1": 0.1477467268705368,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.6182885020492784
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req015",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6978721618652344,
      "sbert_cosine_chunk": 0.6484310626983643,
      "bertscore_f1": 0.07632889598608017,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.5012658353418871
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req016",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4029015302658081,
      "sbert_cosine_chunk": 0.38447868824005127,
      "bertscore_f1": 0.015544776804745197,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req017",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.711837112903595,
      "sbert_cosine_chunk": 0.5674848556518555,
      "bertscore_f1": 0.2584654688835144,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5437713091520254
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req018",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8446721434593201,
      "sbert_cosine_chunk": 0.9198387861251831,
      "bertscore_f1": 0.504562497138977,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req019",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.08164717257022858,
      "sbert_cosine_chunk": 0.28791868686676025,
      "bertscore_f1": 0.1013663113117218,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9469024295259745
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req020",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4832441508769989,
      "sbert_cosine_chunk": 0.48390892148017883,
      "bertscore_f1": 0.1609104871749878,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6309297535714575
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:req021",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5906149744987488,
      "sbert_cosine_chunk": 0.607379138469696,
      "bertscore_f1": 0.03463635966181755,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5437713091520254
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:accel001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6656827926635742,
      "sbert_cosine_chunk": 0.7744155526161194,
      "bertscore_f1": 0.2845245897769928,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:accel002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.909514844417572,
      "sbert_cosine_chunk": 0.6676991581916809,
      "bertscore_f1": 0.44545483589172363,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:accel003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6000316143035889,
      "sbert_cosine_chunk": 0.5791154503822327,
      "bertscore_f1": 0.2923358082771301,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5706417189553201
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:accel004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.37155476212501526,
      "sbert_cosine_chunk": 0.6404374241828918,
      "bertscore_f1": 0.23293715715408325,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.595512330532074,
      "sbert_cosine_chunk": 0.5763609409332275,
      "bertscore_f1": 0.14971594512462616,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9197207891481876
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.060026559978723526,
      "sbert_cosine_chunk": 0.5950251817703247,
      "bertscore_f1": 0.018797045573592186,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.07279493659734726,
      "sbert_cosine_chunk": 0.7100227475166321,
      "bertscore_f1": -0.036245010793209076,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7761290669441223,
      "sbert_cosine_chunk": 0.7208186984062195,
      "bertscore_f1": 0.6347432732582092,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.58427894115448,
      "sbert_cosine_chunk": 0.7228082418441772,
      "bertscore_f1": 0.20851777493953705,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.29745736718177795,
      "sbert_cosine_chunk": 0.4819638729095459,
      "bertscore_f1": 0.03262651339173317,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.2234938144683838,
      "sbert_cosine_chunk": 0.33044517040252686,
      "bertscore_f1": 0.028658034279942513,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5775708556175232,
      "sbert_cosine_chunk": 0.8055140376091003,
      "bertscore_f1": 0.14378777146339417,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9060254355346823
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.08523083478212357,
      "sbert_cosine_chunk": 0.14172878861427307,
      "bertscore_f1": 0.07916726171970367,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.39726194739341736,
      "sbert_cosine_chunk": 0.6424403786659241,
      "bertscore_f1": -0.0013321269070729613,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5706417189553201
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.10443110018968582,
      "sbert_cosine_chunk": 0.6238449811935425,
      "bertscore_f1": 0.02040569856762886,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "biotechnology-industrial-biomedical-sciences-ms:slo012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5146393179893494,
      "sbert_cosine_chunk": 0.7116759419441223,
      "bertscore_f1": 0.06831000000238419,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.6182885020492784
    },
    {
      "id": "cybersecurity-engineering-ms:desc001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6723459959030151,
      "sbert_cosine_chunk": 0.9228350520133972,
      "bertscore_f1": 0.33622997999191284,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9369153380393982,
      "sbert_cosine_chunk": 0.7391063570976257,
      "bertscore_f1": 0.9026283025741577,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.14494915306568146,
      "sbert_cosine_chunk": 0.312963604927063,
      "bertscore_f1": 0.16156382858753204,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5998094081878662,
      "sbert_cosine_chunk": 0.6441564559936523,
      "bertscore_f1": 0.4548267126083374,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4278026223182678,
      "sbert_cosine_chunk": 0.5795255303382874,
      "bertscore_f1": 0.08989208191633224,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7861419916152954,
      "sbert_cosine_chunk": 0.656880259513855,
      "bertscore_f1": 0.7617089152336121,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9828920819566879
    },
    {
      "id": "cybersecurity-engineering-ms:desc007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.14214111864566803,
      "sbert_cosine_chunk": 0.2614423632621765,
      "bertscore_f1": 0.14111045002937317,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5873836278915405,
      "sbert_cosine_chunk": 0.8582665920257568,
      "bertscore_f1": -0.03299945220351219,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5234995484352112,
      "sbert_cosine_chunk": 0.6387031078338623,
      "bertscore_f1": 0.046720150858163834,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8590473532676697,
      "sbert_cosine_chunk": 0.9068313837051392,
      "bertscore_f1": 0.48494434356689453,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3747115135192871,
      "sbert_cosine_chunk": 0.5885147452354431,
      "bertscore_f1": 0.29451411962509155,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3407830595970154,
      "sbert_cosine_chunk": 0.5450383424758911,
      "bertscore_f1": 0.1442129760980606,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc013",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5034486651420593,
      "sbert_cosine_chunk": 0.6466246843338013,
      "bertscore_f1": 0.1750161200761795,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc014",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.601143479347229,
      "sbert_cosine_chunk": 0.5644148588180542,
      "bertscore_f1": 0.3411067724227905,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc015",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6732125878334045,
      "sbert_cosine_chunk": 0.8582665920257568,
      "bertscore_f1": 0.37059685587882996,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "cybersecurity-engineering-ms:desc016",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5094892382621765,
      "sbert_cosine_chunk": 0.49762195348739624,
      "bertscore_f1": 0.1471293866634369,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "cybersecurity-engineering-ms:req001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5966048836708069,
      "sbert_cosine_chunk": 0.5522188544273376,
      "bertscore_f1": 0.20046497881412506,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "cybersecurity-engineering-ms:req002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.30733931064605713,
      "sbert_cosine_chunk": 0.3743545114994049,
      "bertscore_f1": 0.08907945454120636,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.7606395682357036
    },
    {
      "id": "cybersecurity-engineering-ms:req003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5819758772850037,
      "sbert_cosine_chunk": 0.7195204496383667,
      "bertscore_f1": 0.22980213165283203,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:desc001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6595237255096436,
      "sbert_cosine_chunk": 0.6674098968505859,
      "bertscore_f1": 0.6420865654945374,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "information-technology-ms:desc002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.2542206048965454,
      "sbert_cosine_chunk": 0.5500491261482239,
      "bertscore_f1": 0.09858622401952744,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "information-technology-ms:desc003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.20792041718959808,
      "sbert_cosine_chunk": 0.4510285556316376,
      "bertscore_f1": 0.05189821124076843,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6309297535714575
    },
    {
      "id": "information-technology-ms:desc004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7359694242477417,
      "sbert_cosine_chunk": 0.6801823377609253,
      "bertscore_f1": 0.8005867600440979,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "information-technology-ms:desc005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.621446430683136,
      "sbert_cosine_chunk": 0.6966321468353271,
      "bertscore_f1": 0.6800931692123413,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "information-technology-ms:desc006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.47415709495544434,
      "sbert_cosine_chunk": 0.4322817325592041,
      "bertscore_f1": -0.03903675824403763,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8772153153380493
    },
    {
      "id": "information-technology-ms:desc007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.2550705373287201,
      "sbert_cosine_chunk": 0.34543368220329285,
      "bertscore_f1": 0.037799984216690063,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "information-technology-ms:desc008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4325631260871887,
      "sbert_cosine_chunk": 0.5122655630111694,
      "bertscore_f1": 0.25196799635887146,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9674679834891693
    },
    {
      "id": "information-technology-ms:desc009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3480207622051239,
      "sbert_cosine_chunk": 0.517758309841156,
      "bertscore_f1": -0.03083457052707672,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9047172294870751
    },
    {
      "id": "information-technology-ms:req001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6724935173988342,
      "sbert_cosine_chunk": 0.6393694281578064,
      "bertscore_f1": 0.18681278824806213,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.2917381525039673,
      "sbert_cosine_chunk": 0.5156461000442505,
      "bertscore_f1": -0.010144224390387535,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7859353423118591,
      "sbert_cosine_chunk": 0.6218841671943665,
      "bertscore_f1": 0.6145357489585876,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.38685280723454163
    },
    {
      "id": "information-technology-ms:req004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8453049063682556,
      "sbert_cosine_chunk": 0.7685246467590332,
      "bertscore_f1": 0.3085155785083771,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "information-technology-ms:req005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8098631501197815,
      "sbert_cosine_chunk": 0.6018165349960327,
      "bertscore_f1": 0.4320414066314697,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "information-technology-ms:req006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4664200246334076,
      "sbert_cosine_chunk": 0.6272745132446289,
      "bertscore_f1": 0.14429597556591034,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "information-technology-ms:req007",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.633901059627533,
      "sbert_cosine_chunk": 0.6916910409927368,
      "bertscore_f1": 0.08740793913602829,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.38685280723454163
    },
    {
      "id": "information-technology-ms:req008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4934805929660797,
      "sbert_cosine_chunk": 0.49626341462135315,
      "bertscore_f1": 0.042026981711387634,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4604988694190979,
      "sbert_cosine_chunk": 0.4538171887397766,
      "bertscore_f1": 0.05264691263437271,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req010",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3023016154766083,
      "sbert_cosine_chunk": 0.46724793314933777,
      "bertscore_f1": 0.13339067995548248,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "information-technology-ms:req011",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4963749647140503,
      "sbert_cosine_chunk": 0.5255140662193298,
      "bertscore_f1": 0.010246641002595425,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9197207891481876
    },
    {
      "id": "information-technology-ms:req012",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.204925075173378,
      "sbert_cosine_chunk": 0.5266115665435791,
      "bertscore_f1": 0.14572663605213165,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6934264036172708,
      "ndcg@5": 0.7328286204777911
    },
    {
      "id": "information-technology-ms:req013",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5734195709228516,
      "sbert_cosine_chunk": 0.762526273727417,
      "bertscore_f1": 0.08798465132713318,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "information-technology-ms:req014",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.35563141107559204,
      "sbert_cosine_chunk": 0.54051673412323,
      "bertscore_f1": 0.050950322300195694,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req015",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6332412362098694,
      "sbert_cosine_chunk": 0.6014987826347351,
      "bertscore_f1": 0.34017303586006165,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req016",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.2779557704925537,
      "sbert_cosine_chunk": 0.3178248405456543,
      "bertscore_f1": 0.011114006862044334,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "information-technology-ms:req017",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4892180263996124,
      "sbert_cosine_chunk": 0.4619550406932831,
      "bertscore_f1": 0.18875235319137573,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req018",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.2495369166135788,
      "sbert_cosine_chunk": 0.18962743878364563,
      "bertscore_f1": 0.14753800630569458,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "information-technology-ms:req019",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5848679542541504,
      "sbert_cosine_chunk": 0.586024820804596,
      "bertscore_f1": 0.10185897350311279,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.43067655807339306
    },
    {
      "id": "information-technology-ms:req020",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6995516419410706,
      "sbert_cosine_chunk": 0.6850270628929138,
      "bertscore_f1": 0.11370649933815002,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "information-technology-ms:req021",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5585712790489197,
      "sbert_cosine_chunk": 0.7066207528114319,
      "bertscore_f1": 0.1246262639760971,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "accelerated-masters:q0001",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8451390862464905,
      "sbert_cosine_chunk": 0.689376175403595,
      "bertscore_f1": 0.6574639678001404,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "accelerated-masters:q0002",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6656162142753601,
      "sbert_cosine_chunk": 0.6835963129997253,
      "bertscore_f1": 0.25409579277038574,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "accelerated-masters:q0003",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6639111638069153,
      "sbert_cosine_chunk": 0.6778807640075684,
      "bertscore_f1": 0.10346056520938873,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "accelerated-masters:q0004",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.493771493434906,
      "sbert_cosine_chunk": 0.5819162726402283,
      "bertscore_f1": 0.07478593289852142,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "accelerated-masters:q0005",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5529116988182068,
      "sbert_cosine_chunk": 0.7244664430618286,
      "bertscore_f1": 0.20917077362537384,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "accelerated-masters:q0006",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.587151288986206,
      "sbert_cosine_chunk": 0.5280766487121582,
      "bertscore_f1": 0.15868309140205383,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "grading:q0013",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.3298203647136688,
      "sbert_cosine_chunk": 0.6986446380615234,
      "bertscore_f1": 0.01055106706917286,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0014",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5804134607315063,
      "sbert_cosine_chunk": 0.6432670950889587,
      "bertscore_f1": 0.2917537987232208,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0008",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.647816002368927,
      "sbert_cosine_chunk": 0.7421996593475342,
      "bertscore_f1": 0.4701302647590637,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9469024295259745
    },
    {
      "id": "registration:q0009",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6143536567687988,
      "sbert_cosine_chunk": 0.624674379825592,
      "bertscore_f1": 0.4395460784435272,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6309297535714575
    },
    {
      "id": "degree-requirements:q0019",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8183416724205017,
      "sbert_cosine_chunk": 0.8152264356613159,
      "bertscore_f1": 0.5693638324737549,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "admissions:q0174",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7350215911865234,
      "sbert_cosine_chunk": 0.7568681836128235,
      "bertscore_f1": 0.24440962076187134,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.6309297535714575,
      "ndcg@5": 0.6309297535714575
    },
    {
      "id": "admissions:q0175",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4717189073562622,
      "sbert_cosine_chunk": 0.5871209502220154,
      "bertscore_f1": 0.06835485249757767,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "admissions:q0177",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.8834240436553955,
      "sbert_cosine_chunk": 0.872497022151947,
      "bertscore_f1": 0.42673125863075256,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0178",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6312047243118286,
      "sbert_cosine_chunk": 0.8380663394927979,
      "bertscore_f1": 0.24550865590572357,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0179",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.00936080887913704,
      "sbert_cosine_chunk": 0.0,
      "bertscore_f1": 0.028482511639595032,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "campus-life:q0180",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.4075830280780792,
      "sbert_cosine_chunk": 0.881023108959198,
      "bertscore_f1": 0.05511268973350525,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0181",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5504872798919678,
      "sbert_cosine_chunk": 0.8325615525245667,
      "bertscore_f1": 0.12060057371854782,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "fees-financial-support:q0182",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9441134333610535,
      "sbert_cosine_chunk": 0.7641483545303345,
      "bertscore_f1": 0.7644649744033813,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 0.9197207891481876,
      "ndcg@5": 0.9047172294870751
    },
    {
      "id": "fees-financial-support:q0183",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.25775665044784546,
      "sbert_cosine_chunk": 0.5745351314544678,
      "bertscore_f1": -0.14487233757972717,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "fees-financial-support:q0184",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7058164477348328,
      "sbert_cosine_chunk": 0.6939669251441956,
      "bertscore_f1": 0.20413538813591003,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.9558295932317544
    },
    {
      "id": "registration:q0185",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.9293228983879089,
      "sbert_cosine_chunk": 0.9200390577316284,
      "bertscore_f1": 0.43981415033340454,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "courses:q0186",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7090628147125244,
      "sbert_cosine_chunk": 0.886330246925354,
      "bertscore_f1": 0.3018139898777008,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0187",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.9148296117782593,
      "sbert_cosine_chunk": 0.8666674494743347,
      "bertscore_f1": 0.6246834993362427,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0188",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5353785157203674,
      "sbert_cosine_chunk": 0.8412492275238037,
      "bertscore_f1": 0.1453794687986374,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "graduation:q0189",
      "nugget_precision": 1.0,
      "nugget_recall": 0.3333333333333333,
      "nugget_f1": 0.5,
      "sbert_cosine": 0.8528557419776917,
      "sbert_cosine_chunk": 0.7828580141067505,
      "bertscore_f1": 0.5918818116188049,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0190",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6384680271148682,
      "sbert_cosine_chunk": 0.8619011640548706,
      "bertscore_f1": 0.2511797249317169,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "credit-transfer:q0191",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.730322003364563,
      "sbert_cosine_chunk": 0.9458461403846741,
      "bertscore_f1": 0.2920847237110138,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0192",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.41622695326805115,
      "sbert_cosine_chunk": 0.565334141254425,
      "bertscore_f1": 0.10563144832849503,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "degree-requirements:q0193",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.647220253944397,
      "sbert_cosine_chunk": 0.7793963551521301,
      "bertscore_f1": 0.554754912853241,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0194",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.931179404258728,
      "sbert_cosine_chunk": 0.7784286737442017,
      "bertscore_f1": 0.6171661019325256,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "academic-standards:q0196",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6555247902870178,
      "sbert_cosine_chunk": 0.7380750775337219,
      "bertscore_f1": 0.08792073279619217,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5437713091520254
    },
    {
      "id": "grading:q0197",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.9017622470855713,
      "sbert_cosine_chunk": 0.8449711799621582,
      "bertscore_f1": 0.5224950313568115,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "registration:q0198",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.38861167430877686,
      "sbert_cosine_chunk": 0.47952473163604736,
      "bertscore_f1": 0.24177326261997223,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "academic-standards:q0200",
      "nugget_precision": 1.0,
      "nugget_recall": 1.0,
      "nugget_f1": 1.0,
      "sbert_cosine": 0.9823117256164551,
      "sbert_cosine_chunk": 0.7290451526641846,
      "bertscore_f1": 0.8913119435310364,
      "recall@1": 0.5,
      "recall@3": 0.5,
      "recall@5": 0.5,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 0.8503449055347546
    },
    {
      "id": "grading:q0201",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5617985129356384,
      "sbert_cosine_chunk": 0.652004063129425,
      "bertscore_f1": 0.2049042135477066,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "degree-requirements:q0202",
      "nugget_precision": 1.0,
      "nugget_recall": 0.5,
      "nugget_f1": 0.6666666666666666,
      "sbert_cosine": 0.8705204129219055,
      "sbert_cosine_chunk": 0.7069306969642639,
      "bertscore_f1": 0.4855941832065582,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "fees-financial-support:q0203",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5727303624153137,
      "sbert_cosine_chunk": 0.6248145699501038,
      "bertscore_f1": 0.22934232652187347,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "registration:q0199",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.2009419947862625,
      "sbert_cosine_chunk": 0.28949466347694397,
      "bertscore_f1": -0.020643729716539383,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 0.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.0
    },
    {
      "id": "registration:q0200",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.7992337346076965,
      "sbert_cosine_chunk": 0.9002977013587952,
      "bertscore_f1": 0.442808598279953,
      "recall@1": 0.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.5,
      "ndcg@5": 0.5
    },
    {
      "id": "registration:q0201",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6930971741676331,
      "sbert_cosine_chunk": 0.8645142912864685,
      "bertscore_f1": 0.13947920501232147,
      "recall@1": 0.0,
      "recall@3": 0.0,
      "recall@5": 1.0,
      "ndcg@1": 0.0,
      "ndcg@3": 0.0,
      "ndcg@5": 0.43067655807339306
    },
    {
      "id": "degree-requirements:q0203",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.5444203019142151,
      "sbert_cosine_chunk": 0.87859046459198,
      "bertscore_f1": 0.24603240191936493,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    },
    {
      "id": "grading:q0202",
      "nugget_precision": 1.0,
      "nugget_recall": 0.0,
      "nugget_f1": 0.0,
      "sbert_cosine": 0.6608391404151917,
      "sbert_cosine_chunk": 0.7504322528839111,
      "bertscore_f1": 0.21633431315422058,
      "recall@1": 1.0,
      "recall@3": 1.0,
      "recall@5": 1.0,
      "ndcg@1": 1.0,
      "ndcg@3": 1.0,
      "ndcg@5": 1.0
    }
  ],
  "summary": {
    "count": 188,
    "nugget_precision": 1.0,
    "nugget_recall": 0.052304964539007084,
    "nugget_f1": 0.06471631205673758,
    "sbert_cosine": 0.5866891593533627,
    "sbert_cosine_chunk": 0.6631864502708963,
    "bertscore_f1": 0.26330444227193206,
    "recall@1": 0.6223404255319149,
    "recall@3": 0.7712765957446809,
    "recall@5": 0.8191489361702128,
    "ndcg@1": 0.6276595744680851,
    "ndcg@3": 0.7077020223545466,
    "ndcg@5": 0.7262941828485883
  }
}